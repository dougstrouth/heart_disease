{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a600f363",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T17:34:34.051152Z",
     "iopub.status.busy": "2025-08-21T17:34:34.051000Z",
     "iopub.status.idle": "2025-08-21T17:34:34.696599Z",
     "shell.execute_reply": "2025-08-21T17:34:34.696257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "--- Analyzing DataFrame: heart_disease_dataset.csv ---\n",
      "==================================================\n",
      "\n",
      "  Dimensions: 3069 rows, 17 columns\n",
      "\n",
      "  Column Details:\n",
      "    Column Names:\n",
      "      - age\n",
      "      - sex\n",
      "      - cp\n",
      "      - trestbps\n",
      "      - chol\n",
      "      - fbs\n",
      "      - restecg\n",
      "      - thalach\n",
      "      - exang\n",
      "      - oldpeak\n",
      "      - slope\n",
      "      - ca\n",
      "      - thal\n",
      "      - smoking\n",
      "      - diabetes\n",
      "      - bmi\n",
      "      - heart_disease\n",
      "\n",
      "    Data Types:\n",
      "      - age: int64\n",
      "      - sex: int64\n",
      "      - cp: int64\n",
      "      - trestbps: int64\n",
      "      - chol: int64\n",
      "      - fbs: int64\n",
      "      - restecg: int64\n",
      "      - thalach: int64\n",
      "      - exang: int64\n",
      "      - oldpeak: float64\n",
      "      - slope: int64\n",
      "      - ca: int64\n",
      "      - thal: int64\n",
      "      - smoking: int64\n",
      "      - diabetes: int64\n",
      "      - bmi: float64\n",
      "      - heart_disease: int64\n",
      "\n",
      "    Null/Blank Value Percentages (includes NaNs and empty strings for text columns):\n",
      "      - age: 0.00% missing/blank\n",
      "      - sex: 0.00% missing/blank\n",
      "      - cp: 0.00% missing/blank\n",
      "      - trestbps: 0.00% missing/blank\n",
      "      - chol: 0.00% missing/blank\n",
      "      - fbs: 0.00% missing/blank\n",
      "      - restecg: 0.00% missing/blank\n",
      "      - thalach: 0.00% missing/blank\n",
      "      - exang: 0.00% missing/blank\n",
      "      - oldpeak: 0.00% missing/blank\n",
      "      - slope: 0.00% missing/blank\n",
      "      - ca: 0.00% missing/blank\n",
      "      - thal: 0.00% missing/blank\n",
      "      - smoking: 0.00% missing/blank\n",
      "      - diabetes: 0.00% missing/blank\n",
      "      - bmi: 0.00% missing/blank\n",
      "      - heart_disease: 0.00% missing/blank\n",
      "\n",
      "    Potential Date/Time Fields:\n",
      "      - age\n",
      "      - sex\n",
      "      - cp\n",
      "      - trestbps\n",
      "      - chol\n",
      "      - fbs\n",
      "      - restecg\n",
      "      - thalach\n",
      "      - exang\n",
      "      - oldpeak\n",
      "      - slope\n",
      "      - ca\n",
      "      - thal\n",
      "      - smoking\n",
      "      - diabetes\n",
      "      - bmi\n",
      "      - heart_disease\n",
      "\n",
      "      Note: These columns *might* be date/time fields. Confirm with data exploration.\n",
      "      Consider using the 'parse_dates' argument in pd.read_csv() when loading for analysis.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from main import analyze_dataframe\n",
    "# Path to the local CSV file\n",
    "file_path = '/Users/dougstrouth/Documents/datasets/kaggle_data_sets/data/pratyushpuri/heart-disease-dataset-3k-rows-python-code-2025/heart_disease_dataset.csv'\n",
    "\n",
    "try:\n",
    "    # Load the dataset from the local CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Analyze the DataFrame\n",
    "    analyze_dataframe(df, \"heart_disease_dataset.csv\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "002d3f54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T17:34:34.697965Z",
     "iopub.status.busy": "2025-08-21T17:34:34.697871Z",
     "iopub.status.idle": "2025-08-21T17:34:34.705267Z",
     "shell.execute_reply": "2025-08-21T17:34:34.705031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation of columns with heart_disease:\n",
      "heart_disease    1.000000\n",
      "fbs              0.019842\n",
      "bmi              0.015153\n",
      "ca               0.014646\n",
      "chol             0.014417\n",
      "sex              0.007573\n",
      "exang            0.002772\n",
      "thalach          0.002237\n",
      "restecg          0.000615\n",
      "cp              -0.001665\n",
      "diabetes        -0.007073\n",
      "trestbps        -0.011171\n",
      "smoking         -0.011673\n",
      "age             -0.013564\n",
      "thal            -0.023369\n",
      "slope           -0.024752\n",
      "oldpeak         -0.033246\n",
      "Name: heart_disease, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the local CSV file\n",
    "file_path = '/Users/dougstrouth/Documents/datasets/kaggle_data_sets/data/pratyushpuri/heart-disease-dataset-3k-rows-python-code-2025/heart_disease_dataset.csv'\n",
    "\n",
    "try:\n",
    "    # Load the dataset from the local CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Calculate the correlation matrix\n",
    "    correlation_matrix = df.corr()\n",
    "\n",
    "    # Get the correlation of all columns with 'heart_disease'\n",
    "    heart_disease_correlation = correlation_matrix['heart_disease'].sort_values(ascending=False)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Correlation of columns with heart_disease:\")\n",
    "    print(heart_disease_correlation)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1b30372",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T17:34:34.706518Z",
     "iopub.status.busy": "2025-08-21T17:34:34.706406Z",
     "iopub.status.idle": "2025-08-21T17:34:36.021720Z",
     "shell.execute_reply": "2025-08-21T17:34:36.021436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.5439739413680782\n",
      "\n",
      "Feature Importances:\n",
      "chol        0.134566\n",
      "bmi         0.129180\n",
      "trestbps    0.125375\n",
      "thalach     0.123318\n",
      "oldpeak     0.113733\n",
      "age         0.112405\n",
      "cp          0.043055\n",
      "ca          0.036118\n",
      "slope       0.034837\n",
      "restecg     0.033428\n",
      "thal        0.029276\n",
      "sex         0.020107\n",
      "smoking     0.018464\n",
      "exang       0.015847\n",
      "diabetes    0.015736\n",
      "fbs         0.014556\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Path to the local CSV file\n",
    "file_path = '/Users/dougstrouth/Documents/datasets/kaggle_data_sets/data/pratyushpuri/heart-disease-dataset-3k-rows-python-code-2025/heart_disease_dataset.csv'\n",
    "\n",
    "try:\n",
    "    # Load the dataset from the local CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Prepare the data\n",
    "    X = df.drop('heart_disease', axis=1)\n",
    "    y = df['heart_disease']\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train the Random Forest model\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model Accuracy: {accuracy}\")\n",
    "\n",
    "    # Get feature importances\n",
    "    feature_importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "    # Print the feature importances\n",
    "    print(\"\\nFeature Importances:\")\n",
    "    print(feature_importances)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56117f85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T17:34:36.023170Z",
     "iopub.status.busy": "2025-08-21T17:34:36.023067Z",
     "iopub.status.idle": "2025-08-21T17:34:43.991623Z",
     "shell.execute_reply": "2025-08-21T17:34:43.991037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\n",
      "New Model Accuracy: 0.5716612377850163\n",
      "\n",
      "Feature Importances:\n",
      "chol        0.197026\n",
      "thalach     0.154860\n",
      "bmi         0.150782\n",
      "trestbps    0.118887\n",
      "oldpeak     0.112124\n",
      "age         0.109218\n",
      "ca          0.038931\n",
      "slope       0.022326\n",
      "restecg     0.020883\n",
      "cp          0.017167\n",
      "thal        0.016728\n",
      "diabetes    0.014830\n",
      "smoking     0.008696\n",
      "sex         0.007200\n",
      "fbs         0.007086\n",
      "exang       0.003256\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Path to the local CSV file\n",
    "file_path = '/Users/dougstrouth/Documents/datasets/kaggle_data_sets/data/pratyushpuri/heart-disease-dataset-3k-rows-python-code-2025/heart_disease_dataset.csv'\n",
    "\n",
    "try:\n",
    "    # Load the dataset from the local CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Prepare the data\n",
    "    X = df.drop('heart_disease', axis=1)\n",
    "    y = df['heart_disease']\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'max_depth': [3, 4],\n",
    "        'subsample': [0.7, 0.8]\n",
    "    }\n",
    "\n",
    "    # Initialize the Gradient Boosting Classifier\n",
    "    gb_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "    # Initialize GridSearchCV\n",
    "    grid_search = GridSearchCV(estimator=gb_model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "    # Fit GridSearchCV to the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best estimator\n",
    "    best_gb_model = grid_search.best_estimator_\n",
    "\n",
    "    # Evaluate the best model\n",
    "    y_pred = best_gb_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "    print(f\"New Model Accuracy: {accuracy}\")\n",
    "\n",
    "    # Get feature importances\n",
    "    feature_importances = pd.Series(best_gb_model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "    # Print the feature importances\n",
    "    print(\"\\nFeature Importances:\")\n",
    "    print(feature_importances)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
