{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f89be36e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T17:40:03.925066Z",
     "iopub.status.busy": "2025-08-21T17:40:03.924957Z",
     "iopub.status.idle": "2025-08-21T17:40:05.049613Z",
     "shell.execute_reply": "2025-08-21T17:40:05.048618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "--- Analyzing DataFrame: heart_disease_dataset.csv ---\n",
      "==================================================\n",
      "\n",
      "  Dimensions: 3069 rows, 17 columns\n",
      "\n",
      "  Column Details:\n",
      "    Column Names:\n",
      "      - age\n",
      "      - sex\n",
      "      - cp\n",
      "      - trestbps\n",
      "      - chol\n",
      "      - fbs\n",
      "      - restecg\n",
      "      - thalach\n",
      "      - exang\n",
      "      - oldpeak\n",
      "      - slope\n",
      "      - ca\n",
      "      - thal\n",
      "      - smoking\n",
      "      - diabetes\n",
      "      - bmi\n",
      "      - heart_disease\n",
      "\n",
      "    Data Types:\n",
      "      - age: int64\n",
      "      - sex: int64\n",
      "      - cp: int64\n",
      "      - trestbps: int64\n",
      "      - chol: int64\n",
      "      - fbs: int64\n",
      "      - restecg: int64\n",
      "      - thalach: int64\n",
      "      - exang: int64\n",
      "      - oldpeak: float64\n",
      "      - slope: int64\n",
      "      - ca: int64\n",
      "      - thal: int64\n",
      "      - smoking: int64\n",
      "      - diabetes: int64\n",
      "      - bmi: float64\n",
      "      - heart_disease: int64\n",
      "\n",
      "    Null/Blank Value Percentages (includes NaNs and empty strings for text columns):\n",
      "      - age: 0.00% missing/blank\n",
      "      - sex: 0.00% missing/blank\n",
      "      - cp: 0.00% missing/blank\n",
      "      - trestbps: 0.00% missing/blank\n",
      "      - chol: 0.00% missing/blank\n",
      "      - fbs: 0.00% missing/blank\n",
      "      - restecg: 0.00% missing/blank\n",
      "      - thalach: 0.00% missing/blank\n",
      "      - exang: 0.00% missing/blank\n",
      "      - oldpeak: 0.00% missing/blank\n",
      "      - slope: 0.00% missing/blank\n",
      "      - ca: 0.00% missing/blank\n",
      "      - thal: 0.00% missing/blank\n",
      "      - smoking: 0.00% missing/blank\n",
      "      - diabetes: 0.00% missing/blank\n",
      "      - bmi: 0.00% missing/blank\n",
      "      - heart_disease: 0.00% missing/blank\n",
      "\n",
      "    Potential Date/Time Fields:\n",
      "      - age\n",
      "      - sex\n",
      "      - cp\n",
      "      - trestbps\n",
      "      - chol\n",
      "      - fbs\n",
      "      - restecg\n",
      "      - thalach\n",
      "      - exang\n",
      "      - oldpeak\n",
      "      - slope\n",
      "      - ca\n",
      "      - thal\n",
      "      - smoking\n",
      "      - diabetes\n",
      "      - bmi\n",
      "      - heart_disease\n",
      "\n",
      "      Note: These columns *might* be date/time fields. Confirm with data exploration.\n",
      "      Consider using the 'parse_dates' argument in pd.read_csv() when loading for analysis.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from main import analyze_dataframe\n",
    "# Path to the local CSV file\n",
    "file_path = '/Users/dougstrouth/Documents/datasets/kaggle_data_sets/data/pratyushpuri/heart-disease-dataset-3k-rows-python-code-2025/heart_disease_dataset.csv'\n",
    "\n",
    "try:\n",
    "    # Load the dataset from the local CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Analyze the DataFrame\n",
    "    analyze_dataframe(df, \"heart_disease_dataset.csv\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "360d2077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T17:40:05.053417Z",
     "iopub.status.busy": "2025-08-21T17:40:05.053221Z",
     "iopub.status.idle": "2025-08-21T17:40:05.069332Z",
     "shell.execute_reply": "2025-08-21T17:40:05.067850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation of columns with heart_disease:\n",
      "heart_disease    1.000000\n",
      "fbs              0.019842\n",
      "bmi              0.015153\n",
      "ca               0.014646\n",
      "chol             0.014417\n",
      "sex              0.007573\n",
      "exang            0.002772\n",
      "thalach          0.002237\n",
      "restecg          0.000615\n",
      "cp              -0.001665\n",
      "diabetes        -0.007073\n",
      "trestbps        -0.011171\n",
      "smoking         -0.011673\n",
      "age             -0.013564\n",
      "thal            -0.023369\n",
      "slope           -0.024752\n",
      "oldpeak         -0.033246\n",
      "Name: heart_disease, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the local CSV file\n",
    "file_path = '/Users/dougstrouth/Documents/datasets/kaggle_data_sets/data/pratyushpuri/heart-disease-dataset-3k-rows-python-code-2025/heart_disease_dataset.csv'\n",
    "\n",
    "try:\n",
    "    # Load the dataset from the local CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Calculate the correlation matrix\n",
    "    correlation_matrix = df.corr()\n",
    "\n",
    "    # Get the correlation of all columns with 'heart_disease'\n",
    "    heart_disease_correlation = correlation_matrix['heart_disease'].sort_values(ascending=False)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Correlation of columns with heart_disease:\")\n",
    "    print(heart_disease_correlation)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68459a41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T17:40:05.072776Z",
     "iopub.status.busy": "2025-08-21T17:40:05.072426Z",
     "iopub.status.idle": "2025-08-21T17:40:06.622421Z",
     "shell.execute_reply": "2025-08-21T17:40:06.622084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.5439739413680782\n",
      "\n",
      "Feature Importances:\n",
      "chol        0.134566\n",
      "bmi         0.129180\n",
      "trestbps    0.125375\n",
      "thalach     0.123318\n",
      "oldpeak     0.113733\n",
      "age         0.112405\n",
      "cp          0.043055\n",
      "ca          0.036118\n",
      "slope       0.034837\n",
      "restecg     0.033428\n",
      "thal        0.029276\n",
      "sex         0.020107\n",
      "smoking     0.018464\n",
      "exang       0.015847\n",
      "diabetes    0.015736\n",
      "fbs         0.014556\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Path to the local CSV file\n",
    "file_path = '/Users/dougstrouth/Documents/datasets/kaggle_data_sets/data/pratyushpuri/heart-disease-dataset-3k-rows-python-code-2025/heart_disease_dataset.csv'\n",
    "\n",
    "try:\n",
    "    # Load the dataset from the local CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Prepare the data\n",
    "    X = df.drop('heart_disease', axis=1)\n",
    "    y = df['heart_disease']\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train the Random Forest model\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model Accuracy: {accuracy}\")\n",
    "\n",
    "    # Get feature importances\n",
    "    feature_importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "    # Print the feature importances\n",
    "    print(\"\\nFeature Importances:\")\n",
    "    print(feature_importances)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dacbd14f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T17:40:06.624420Z",
     "iopub.status.busy": "2025-08-21T17:40:06.624286Z",
     "iopub.status.idle": "2025-08-21T17:40:19.022791Z",
     "shell.execute_reply": "2025-08-21T17:40:19.021664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\n",
      "New Model Accuracy: 0.5716612377850163\n",
      "\n",
      "Feature Importances:\n",
      "chol        0.197026\n",
      "thalach     0.154860\n",
      "bmi         0.150782\n",
      "trestbps    0.118887\n",
      "oldpeak     0.112124\n",
      "age         0.109218\n",
      "ca          0.038931\n",
      "slope       0.022326\n",
      "restecg     0.020883\n",
      "cp          0.017167\n",
      "thal        0.016728\n",
      "diabetes    0.014830\n",
      "smoking     0.008696\n",
      "sex         0.007200\n",
      "fbs         0.007086\n",
      "exang       0.003256\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Path to the local CSV file\n",
    "file_path = '/Users/dougstrouth/Documents/datasets/kaggle_data_sets/data/pratyushpuri/heart-disease-dataset-3k-rows-python-code-2025/heart_disease_dataset.csv'\n",
    "\n",
    "try:\n",
    "    # Load the dataset from the local CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Prepare the data\n",
    "    X = df.drop('heart_disease', axis=1)\n",
    "    y = df['heart_disease']\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'max_depth': [3, 4],\n",
    "        'subsample': [0.7, 0.8]\n",
    "    }\n",
    "\n",
    "    # Initialize the Gradient Boosting Classifier\n",
    "    gb_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "    # Initialize GridSearchCV\n",
    "    grid_search = GridSearchCV(estimator=gb_model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "    # Fit GridSearchCV to the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best estimator\n",
    "    best_gb_model = grid_search.best_estimator_\n",
    "\n",
    "    # Evaluate the best model\n",
    "    y_pred = best_gb_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "    print(f\"New Model Accuracy: {accuracy}\")\n",
    "\n",
    "    # Get feature importances\n",
    "    feature_importances = pd.Series(best_gb_model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "    # Print the feature importances\n",
    "    print(\"\\nFeature Importances:\")\n",
    "    print(feature_importances)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77c5c3a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T17:40:19.031007Z",
     "iopub.status.busy": "2025-08-21T17:40:19.030719Z",
     "iopub.status.idle": "2025-08-21T17:40:20.413455Z",
     "shell.execute_reply": "2025-08-21T17:40:20.413114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[334  31]\n",
      " [232  17]]\n",
      "\n",
      "Misclassified Samples:\n",
      "      age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "2651   56    1   2       101   492    0        0      197      0      4.8   \n",
      "1740   57    1   3       170   539    1        1      155      0      1.2   \n",
      "2606   51    1   4       148   371    0        2      143      0      1.0   \n",
      "2164   41    1   1       110   592    0        2      140      0      6.0   \n",
      "2119   57    1   2        97   550    0        0      185      0      0.9   \n",
      "\n",
      "      slope  ca  thal  smoking  diabetes   bmi  true_label  predicted_label  \n",
      "2651      3   0     3        1         0  24.1           1                0  \n",
      "1740      2   0     6        0         0  34.8           1                0  \n",
      "2606      3   0     3        0         1  39.4           1                0  \n",
      "2164      1   0     3        0         1  29.8           1                0  \n",
      "2119      1   0     3        0         1  37.8           1                0  \n",
      "\n",
      "Analysis of Misclassified Samples:\n",
      "              age         sex          cp    trestbps        chol         fbs  \\\n",
      "count  263.000000  263.000000  263.000000  263.000000  263.000000  263.000000   \n",
      "mean    52.980989    0.558935    2.448669  142.661597  360.007605    0.167300   \n",
      "std     13.563943    0.497461    1.089606   32.040342  153.053974    0.373955   \n",
      "min     29.000000    0.000000    1.000000   90.000000  107.000000    0.000000   \n",
      "25%     42.000000    0.000000    1.000000  112.500000  218.500000    0.000000   \n",
      "50%     52.000000    1.000000    2.000000  142.000000  364.000000    0.000000   \n",
      "75%     65.000000    1.000000    3.000000  171.000000  501.500000    0.000000   \n",
      "max     76.000000    1.000000    4.000000  200.000000  600.000000    1.000000   \n",
      "\n",
      "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
      "count  263.000000  263.000000  263.000000  263.000000  263.000000  263.000000   \n",
      "mean     1.015209  136.593156    0.171103    3.080989    1.984791    0.536122   \n",
      "std      0.795836   43.769847    0.377317    1.745447    0.824110    0.836676   \n",
      "min      0.000000   60.000000    0.000000    0.000000    1.000000    0.000000   \n",
      "25%      0.000000  101.000000    0.000000    1.600000    1.000000    0.000000   \n",
      "50%      1.000000  140.000000    0.000000    3.000000    2.000000    0.000000   \n",
      "75%      2.000000  174.000000    0.000000    4.600000    3.000000    1.000000   \n",
      "max      2.000000  209.000000    1.000000    6.200000    3.000000    3.000000   \n",
      "\n",
      "             thal     smoking    diabetes         bmi  true_label  \\\n",
      "count  263.000000  263.000000  263.000000  263.000000  263.000000   \n",
      "mean     4.509506    0.368821    0.209125   27.645627    0.882129   \n",
      "std      1.733952    0.483405    0.407460    7.185703    0.323070   \n",
      "min      3.000000    0.000000    0.000000   15.300000    0.000000   \n",
      "25%      3.000000    0.000000    0.000000   21.000000    1.000000   \n",
      "50%      3.000000    0.000000    0.000000   28.300000    1.000000   \n",
      "75%      6.000000    1.000000    0.000000   34.100000    1.000000   \n",
      "max      7.000000    1.000000    1.000000   39.900000    1.000000   \n",
      "\n",
      "       predicted_label  \n",
      "count       263.000000  \n",
      "mean          0.117871  \n",
      "std           0.323070  \n",
      "min           0.000000  \n",
      "25%           0.000000  \n",
      "50%           0.000000  \n",
      "75%           0.000000  \n",
      "max           1.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/km/5qt3ls3s1qn70cv5nfmzvy6m0000gn/T/ipykernel_16099/1492440689.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  misclassified_samples['true_label'] = y_test.iloc[misclassified_indices]\n",
      "/var/folders/km/5qt3ls3s1qn70cv5nfmzvy6m0000gn/T/ipykernel_16099/1492440689.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  misclassified_samples['predicted_label'] = y_pred[misclassified_indices]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Path to the local CSV file\n",
    "file_path = '/Users/dougstrouth/Documents/datasets/kaggle_data_sets/data/pratyushpuri/heart-disease-dataset-3k-rows-python-code-2025/heart_disease_dataset.csv'\n",
    "\n",
    "try:\n",
    "    # Load the dataset from the local CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Prepare the data\n",
    "    X = df.drop('heart_disease', axis=1)\n",
    "    y = df['heart_disease']\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Get the predictions on the test set\n",
    "    y_pred = best_gb_model.predict(X_test)\n",
    "\n",
    "    # Create a confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Identify the misclassified samples\n",
    "    misclassified_indices = np.where(y_test != y_pred)[0]\n",
    "    misclassified_samples = X_test.iloc[misclassified_indices]\n",
    "    misclassified_samples['true_label'] = y_test.iloc[misclassified_indices]\n",
    "    misclassified_samples['predicted_label'] = y_pred[misclassified_indices]\n",
    "\n",
    "    # Print the first few misclassified samples\n",
    "    print(\"\\nMisclassified Samples:\")\n",
    "    print(misclassified_samples.head())\n",
    "\n",
    "    # Analyze the misclassified samples\n",
    "    print(\"\\nAnalysis of Misclassified Samples:\")\n",
    "    print(misclassified_samples.describe())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd401879",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T17:40:20.415539Z",
     "iopub.status.busy": "2025-08-21T17:40:20.415239Z",
     "iopub.status.idle": "2025-08-21T17:40:20.431931Z",
     "shell.execute_reply": "2025-08-21T17:40:20.431556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptive Statistics of the Entire Dataset:\n",
      "              age          sex           cp     trestbps         chol  \\\n",
      "count  3069.00000  3069.000000  3069.000000  3069.000000  3069.000000   \n",
      "mean     52.50114     0.555556     2.489736   145.306289   347.219941   \n",
      "std      13.70752     0.496985     1.110417    31.602321   146.853319   \n",
      "min      29.00000     0.000000     1.000000    90.000000   100.000000   \n",
      "25%      41.00000     0.000000     2.000000   118.000000   215.000000   \n",
      "50%      53.00000     1.000000     2.000000   146.000000   350.000000   \n",
      "75%      64.00000     1.000000     3.000000   172.000000   475.000000   \n",
      "max      76.00000     1.000000     4.000000   200.000000   600.000000   \n",
      "\n",
      "               fbs      restecg      thalach        exang      oldpeak  \\\n",
      "count  3069.000000  3069.000000  3069.000000  3069.000000  3069.000000   \n",
      "mean      0.145650     1.004236   135.157380     0.176279     3.189052   \n",
      "std       0.352813     0.812016    43.353197     0.381119     1.802815   \n",
      "min       0.000000     0.000000    60.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000    98.000000     0.000000     1.600000   \n",
      "50%       0.000000     1.000000   135.000000     0.000000     3.200000   \n",
      "75%       0.000000     2.000000   172.000000     0.000000     4.700000   \n",
      "max       1.000000     2.000000   210.000000     1.000000     6.200000   \n",
      "\n",
      "             slope           ca         thal      smoking     diabetes  \\\n",
      "count  3069.000000  3069.000000  3069.000000  3069.000000  3069.000000   \n",
      "mean      2.023786     0.626588     4.544477     0.348974     0.193874   \n",
      "std       0.817679     0.891447     1.751064     0.476723     0.395396   \n",
      "min       1.000000     0.000000     3.000000     0.000000     0.000000   \n",
      "25%       1.000000     0.000000     3.000000     0.000000     0.000000   \n",
      "50%       2.000000     0.000000     3.000000     0.000000     0.000000   \n",
      "75%       3.000000     1.000000     6.000000     1.000000     0.000000   \n",
      "max       3.000000     3.000000     7.000000     1.000000     1.000000   \n",
      "\n",
      "               bmi  heart_disease  \n",
      "count  3069.000000    3069.000000  \n",
      "mean     27.496839       0.403715  \n",
      "std       7.281731       0.490721  \n",
      "min      15.000000       0.000000  \n",
      "25%      21.300000       0.000000  \n",
      "50%      27.400000       0.000000  \n",
      "75%      33.900000       1.000000  \n",
      "max      40.000000       1.000000  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the local CSV file\n",
    "file_path = '/Users/dougstrouth/Documents/datasets/kaggle_data_sets/data/pratyushpuri/heart-disease-dataset-3k-rows-python-code-2025/heart_disease_dataset.csv'\n",
    "\n",
    "try:\n",
    "    # Load the dataset from the local CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Print the descriptive statistics of the entire dataset\n",
    "    print(\"\\nDescriptive Statistics of the Entire Dataset:\")\n",
    "    print(df.describe())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
